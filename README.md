# FileLine Expriment Manager

本项目旨在简化科研工作中的数据处理流程（画图流程也被视为数据处理流程的一种），提升数据处理效率。

## 解决的核心问题

- 原始数据格式各样，难以统一处理流程。

    实验过程中产生的原始数据格式各种各样，为了满足实验需求更是会引入大量自定义的逻辑，都需要逐一编写处理代码。因此通过简化新文件处理功能的开发难度，提升数据处理效率，用最少的开发量实现数据处理流程的自动化。

- 自动化管理数据处理流程。

    实验过程中，会产生大量数据处理操作，这些操作的输入，参数，以及处理代码的版本都各不相同，手动管理这些操作会耗费大量时间。因此通过自动化管理数据处理流程，降低管理成本。

- 自动缓存已处理过的操作，避免重复处理。

    实验过程中产生的很多操作，都有相同的输入，参数，以及处理代码的版本，因此可以通过自动缓存已处理过的操作，避免重复处理，提升数据处理效率。

- 数据文件版本管理困难。

    实验过程中，会产生大量同名的原始数据，中间处理数据，如果都靠手动管理版本，会造成管理困难。因此通过自动代码历史记录保存，可追溯数据处理过程，提升数据处理效率。

## 核心功能

- 自定义yaml配置文件，实现数据处理流程的自动化。
- 自动代码历史记录保存，可追溯数据处理过程。
- 自动缓存已处理过的操作，若数据处理操作的输入、参数、以及代码版本不变，则可避免重复处理。
- 简化扩展新文件处理功能的开发难度，只需要带上注册注解即可。
- 将所有文件处理操作分为单输入单输出，多输入单输出两类，通过自定义pipeline组合，实现任意数据处理流程的自动化。

## 使用方法

- 确认所需处理过程是否实现(processes目录下)，且使用了ProcessorRegistry.register注解。

- 将各个处理步骤组合成pipeline，并在yaml配置文件中配置。

- 运行main.py，即可实现数据处理流程的自动化。(详细命令可通过python main.py --help查看)

## 参考样例

- 首先创建并使用新实验

    ```
        python main.py experiment create demo
        python main.py experiment use demo
    ```

- 流水线配置文件见examples目录下, 包括单输入单输出样例（test.yaml）, 多输入单输出绘图样例（loss_curve.yaml）,占位符控制样例（loss_curve_var.yaml）及其对应全局配置文件（loss_curve_var.global）。所有被调用的processor应当提前注册到ProcessorRegistry中（processes目录下）。

- 运行流水线

    ```
        Usage: main.py pipeline run [OPTIONS] CONFIG_FILE

        运行带文件加载的流水线

        Options:
        --global-config PATH  全局配置文件路径（包含变量定义）
        --debug / --no-debug
        --help                Show this message and exit.
    ```